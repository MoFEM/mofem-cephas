/*! \page faqs Frequently Asked Questions

\tableofcontents

\section faq_general General

\subsection mofem_citation How to cite us?

If you write a paper using results obtained with the help of MoFEM, please
cite our publication in \em The \em Journal \em of \em Open \em Source \em Software
\htmlonly
<a href="http://joss.theoj.org/papers/43d9625e5ed28d5c493bfc0fae6d8215"><img src="http://joss.theoj.org/papers/43d9625e5ed28d5c493bfc0fae6d8215/status.svg"></a>
\endhtmlonly
(follow link on the badge).

The BibTex entry for MoFEM paper \cite mofemJoss is 
\code
@article{mofemJoss2020,
  title = {{MoFEM:} An open source, parallel finite element library},
  author = {
    Kaczmarczyk, {\L}ukasz and Ullah, Zahur and Lewandowski, Karol and Meng, 
    Xuan and	Zhou, Xiao-Yi and Athanasiadis, Ignatios and Nguyen, 
    Hoang  and	Chalons-Mouriesse, Christophe-Alexandre and Richardson, 
    Euan and Miur, Euan and Shvarts, Andrei and Wakeni,Mebratu and Pearce, Chris},
  journal={The Journal of Open Source Software},
  year={2020},
  note={http://mofem.eng.gla.ac.uk},
  doi={10.21105/joss.01441},
  url={https://joss.theoj.org/papers/10.21105/joss.01441}
}
\endcode

\note Each user module can have own DOI and reference. All module references
supplements  MoFEM reference. For example homogenisation module DOI is on the badge
\htmlonly
<a href="https://doi.org/10.5281/zenodo.439368"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.439368.svg" alt="DOI"></a>
\endhtmlonly
.

\endhtmlonly

\subsection policy_of_for_version How MoFEM version is changed?

The current MoFEM version can be identified by \e Semantic \e Versioning and \e
Git \e Commit \e Id. \e Git \e Commit \e Id is unique and points to particular
code commit. \e Semantic \e Versioning is not unique, more than one commits to git
repository can have the same version.

First two lines of every executed code which is build with MoFEM library look like that
\code
version 0.3.24  <---  (MAJOR_VERSION.MINOR_VERSION.BUILD_VERSION)
git commit id 3d06924d27973df16e3260c6e962929330cf9348
\endcode
That allows to identify \em git commit id and human readable MoFEM version.

MoFEM is developed continuously (see \ref validation_and_verfication) and any
commit which introducing changes that directly have an impact on users
modules implementation should result in increment \e build \e version. For
example if new functionality is added, name of interface function changed or
some function deprecated etc. that will result in incremented build version.
Note that each users module has set minimal MoFEM version to which is
compatible, see \ref adding_user_module for details.

On the other hand changes/improvements to core library like modification of local
variable name or when local documentation added, that will result in new commit
however will NOT result in new \e build \e version, since implementation of
users modules is not influenced by changes in main library.

Build version is in range from 0-100, at the end of the range minor version
should be automatically incremented. Minor version is in the range from 0-10, at
the end of the range major version should be automatically incremented. The
minor or major version could be changed at any time when major/minor feature is
initiated.

In addition to above rules, the general principles could apply, in short,
- 3.7.11 (bug fix), incremental change in build version
- 3.7.12 (partial new feature, hidden behind a Feature Toggle.), incremental change in build version
- 3.7.13 (performance improvement), incremental change in build version
- 3.8.0 (completed feature initiated in 3.7.12), direct change in minor version
- 4.0.0 (breaking changes in public API), direct change in major version

\subsection validation_and_verfication How MoFEM is developed?

MoFEM is developed continuously, i.e. any merged pull request to the
CDashTesting branch triggers automatic testing on the development server. The
code is verified during when a pull request is accepted and merged and validated
when the test on the development server are passed. If tests are passed
CDashBranch is merged to master branch.

\subsection mbconvert How to convert output h5m files to the vtk format?
In order to convert a single \em h5m file to \em vtk, you can use the \em mbconvert tool:
\code
mbconvert out.h5m out.vtk
\endcode
Moreover, to convert a set of files with one command you can use a multiprocessing script convert.py:
\code
$USER_MODULES/tools/convert.py -np 2 out*
\endcode
The above command will convert all \em h5m files in the current directory having name starting with "out" to \em vtk files with the same name, using a pool of two processes. 
To see all parameters of the script and their descriptions you can run:
\code
$USER_MODULES/tools/convert.py -h
\endcode
Note that the script is compatible with both \em Python \em 2.x and \em 3.x.

\subsection partition_mesh How to partition mesh?

If problem is large, mesh can be partitioned for to save memory and improve efficiency. This can be done using native MoFEM tool,
\code
$USER_MODULES/tools/mofem_part -my_file $USER_MODULES/basic_finite_elements/nonlinear_elasticity/examples/cylinder.cub -my_nparts 16
\endcode
The partitioned mesh is saved to file *out.h5m* in current working directory.

For large meshes, partitioning can be in parallel, for example
\code
mpirun -np 2 $USER_MODULES/tools/mofem_part -my_file $USER_MODULES/basic_finite_elements/nonlinear_elasticity/examples/cylinder.cub -my_nparts 16
\endcode

\subsection running_multi_grid How to run multi-grid solver via approximation orders?

Code is run using direct solver, i.e. \em MUMPS on coarse level. Note that
loaded mesh is portioned and each processor only reads part of the mesh, i.e.
\em  -my_is_partitioned.

\code
mpirun -np 4 ./elasticity \
  -my_file dam_4parts.h5m -my_is_partitioned \
  -ksp_type gmres -ksp_max_it 1000  -ksp_atol 1e-13 -ksp_rtol 0  -ksp_monitor_lg_residualnorm  -ksp_final_residual -ksp_monitor -ksp_converged_reason
  -my_order 1  -my_block_config block_congig.in   \
  -mofem_mg_verbose 1 -mofem_mg_coarse_order 1 -mofem_mg_levels 4  \
  -pc_type mg \
  -mg_coarse_ksp_type preonly -mg_coarse_pc_type lu -mg_coarse_pc_factor_mat_solver_type mumps \
  -pc_mg_smoothup 20 -pc_mg_smoothdown 20  -pc_mg_type multiplicative
\endcode

- Option \em -my_is_partitioned is set if mesh is partitioned using \em mbpart
- Option \em -mofem_mg_coarse_order 1 set coarse level is for linear approximation, i.e. order 1.
- Option \em -mofem_mg_levels 4 set number of multi-grid level. In that case maximal approx. order for some part of mesh is 4, thus 4 multi-grid levels.
- Option -pc_mg_smoothup 20 -pc_mg_smoothdown 20 set number of smoothing iterations, for more details look to PETSc manual.
- In line \code
-mg_coarse_ksp_type preonly -mg_coarse_pc_type lu -mg_coarse_pc_factor_mat_solver_type mumps
\endcode a direct solver for coarse mesh is set.

\subsection how_to_make_2nd_order_geometry How to make 2nd order geometry in cubit and transfer it to MoFEM?

In cubit you need to generate 10 node tetrahedral. You simply create block
and set element type to TETRA10, as follows
\code
set duplicate block elements on
block 2 volume 1
block 2 element type TETRA10
\endcode

In the code, you need to create field to keep geometry
\code
CHKERR m_field.add_field("MESH_NODE_POSITIONS",H1,3,MF_ZERO);
CHKERR m_field.add_ents_to_field_by_TETs(0,"MESH_NODE_POSITIONS",2); 
\endcode
Next set order of approximation field. If you have 10 node tetrahedrons, you
need to have at least 2nd order polynomials to approximate geometry;
\code
CHKERR m_field.set_field_order(0,MBTET,"MESH_NODE_POSITIONS",2);
CHKERR m_field.set_field_order(0,MBTRI,"MESH_NODE_POSITIONS",2);
CHKERR m_field.set_field_order(0,MBEDGE,"MESH_NODE_POSITIONS",2);
CHKERR m_field.set_field_order(0,MBVERTEX,"MESH_NODE_POSITIONS",1);
\endcode

The last step is to prject information from 10 node terahedrons on
hierarchical approximation field, as follows
\code
Projection10NodeCoordsOnField ent_method_material(m_field,"MESH_NODE_POSITIONS");
CHKERR m_field.loop_dofs("MESH_NODE_POSITIONS",ent_method_material); 
\endcode

Look at examples of use to user modules, for example elasticity.cpp.

\subsection own_documentation How to generate this documentation on your local machine?

In you library directory execute
\code
make doc
\endcode
This create directory \em html. Open file \em html/index.html to see results in your browser.

\subsection msteam_message_send Use webhook to send message to Microsoft Teams

Similar process to send message to MS Teams can be done using their APIs

\code
TITLE="Title of your message"
MESSAGE="Body of your message"
JSON="{\"title\": \"${TITLE}\", \"text\": \"${MESSAGE}\" }"
WEBHOOK_URL="https://outlook.office.com/webhook/abcd1234xyz"
 
curl -H "Content-Type: application/json" -d "${JSON}" "${WEBHOOK_URL}"
\endcode

Where WEBHOOK_URL is the webhook URL of the Teams channel to which the message
will be sent. To get webhook URL click on the three-dot sign (next to a channel
name) -> Connectors -> Configure (Incoming Webhook) -> Give a name and click
Create -> Copy the URL.

\section faq_post_processing Postprocessing 

\subsection Postporcessing on refined post-proc mesh with PostProcGenerateRefMeshBase and derived classes

If higher approximation orders are used is sometimes required to refine mesh used to postprocessing to visualise higher order polynomials fields. Classes derived from PostProcGenerateRefMeshBase enable adaptive refinement, such that elements only with high orders are refined. To set refinement, use the command line option.
\code
-max_post_proc_ref_level 2
\endcode
Above results int to refinment levels,

\section faq_git Git and repository

\subsection users_modules_changes_affects_mainRepo Why do users_modules changes affect mofem-cephas/mofem git repository?

When making changes in a users_modules, a git submodule, the main git repo
will register a version change. For example:
\code
cd mofem-cephas/mofem
git diff

diff --git a/mofem/users_modules b/mofem/users_modules
index d18f43f88..42bcece0e 160000
--- a/mofem/users_modules
+++ b/mofem/users_modules
@@ -1 +1 @@
-Subproject commit d18f43f884bfbfbce50f0f70155d911a2d361164
+Subproject commit 42bcece0e7e6577b83bb2a5c64d2709a2bc15b47
\endcode

The commi t ID of the submodule is used to track which version to pull when
pulling the main repo. Updating to the latest commit will then pull the your
latest changes.

\subsection git_squash Squashing for an external PR

It is good practice to squash commits before the merge. That simplifies reviews and
makes the git commits tree easier to browse and understand. Details on how to
squash commits you will find here \ref SquashFAQ.

\section faq_profiling Profiling

\subsection faq_profiling_valgrind How to check for memory leaks and other bugs with Valgrind?

Look to Valgrind <a href=http://valgrind.org>documentation</a>. However, a
quick answer is
\code
valgrind \
--dsymutil=yes \
--track-origins=yes \
--trace-children=yes \
--show-leak-kinds=all \
--verbose \
--log-file=valgrind-out.txt \
./command args
\endcode

\subsection faq_gdb_mpi How to debug a multiprocessing program?

In order to debug a multiprocessing program, one can still use a serial debugger (such as \em gdb) as follows:
\code
mpirun -np 4 xterm -e gdb ./program
\endcode
The command above will open 4 \em xterm windows, each running one process of the program in \em gdb. If the program requires arguments, they can be passed manually to each process by typing:
\code
run [arg1] [arg2] [arg3]
\endcode
in each window. Alternatively, the following command can be used to automatically pass arguments to all processes:
\code
mpirun -np 4 xterm -e gdb -ex run --args ./program [arg1] [arg2] [arg3]
\endcode
See OpenMPI <a href=https://www.open-mpi.org/faq/?category=debugging>documentation</a> for more details.

If you using \em lldb, that is usally a case of Mac OSX, you run debugging as follows:
\code
mpirun -np 4 xterm -e lldb -- ./program [arg1] [arg2] [arg3]
\endcode 

\subsection faq_memory_profiling_valgrind How to profile memory usage?

Valgrind comes with a tool for measuring memory usage: 
<a href=http://valgrind.org/docs/manual/ms-manual.html>massif</a>. Example usage:

\code
valgrind --trace-children=yes --tool=massif --pages-as-heap=yes ./command args
\endcode

This generates massif.out files that can be visualised with a graph using 
<a href=http://valgrind.org/docs/manual/ms-manual.html#ms-manual.running-ms_print>ms_print</a>.

\code
ms_print massif.out
\endcode

\subsection faq_profiling_code_mac_os_x How to profile code using Xcode tools?

To profile code in macOS environment, from line command you execute \em instruments,
for example
\code
instruments -v -t "Time Profiler" \
./elasticity -my_file LShape.h5m  -ksp_type fgmres -ksp_monitor -my_order 5 \
-pc_type mg -mofem_mg_verbose 1 -mofem_mg_coarse_order 1 \
-mofem_mg_levels 5 -mg_coarse_ksp_type preonly \
-mg_coarse_pc_type lu -mg_coarse_pc_factor_mat_solver_type mumps \
-pc_mg_smoothup 10 -pc_mg_smoothdown 10 -pc_mg_type multiplicative -log_view
\endcode

This generates directory \em instrumentscli0.trace and for next run
\em instrumentscli1.trace, and similarly for subsequent runs. You can see changes
in execution of the code by
\code
open instrumentscli0.trace
\endcode

If you use Linux you can alternatively use Valgrind, see \ref profiling_code_with_valgrind.

\subsection profiling_code_stages How to profile code using PETSc tools?

See PETSc documentation
<http://www.mcs.anl.gov/petsc/petsc-current/docs/manualpages/Profiling/PetscLogStageRegister.html>
and examples
<http://www.mcs.anl.gov/petsc/petsc-current/src/ksp/ksp/examples/tutorials/ex9.c.html>

\subsection faq_profiling_petsc_log_events How to time and log events with PETSC?

PETSC is capable of timing events and displaying their collective output. To create a new event
requires 
<a href=https://www.mcs.anl.gov/petsc/petsc-current/docs/manualpages/Profiling/PetscLogEventRegister.html>registering</a>
the event and add this to run time commands:
\code -log_view \endcode

Example output:

\code
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                             --- Global ---  --- Stage ---   Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   Avg len Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSidedF        17 1.0 1.2918e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
LoadMesh               1 1.0 1.6751e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 15  0  0  0  0  15  0  0  0  0     0
buildFields            1 1.0 4.5471e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
buildFiniteElements       1 1.0 7.8488e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  7  0  0  0  0   7  0  0  0  0     0
SimpleSetUp            1 1.0 3.4389e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
ProblemsManager        1 1.0 2.9552e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
\endcode

\subsection profiling_code_with_valgrind How to profile code with Valgrind?

You have to install Valgrind <http://valgrind.org> and graphic user interface
KCachegrind <http://kcachegrind.sourceforge.net/html/Home.html>. If you using Linux,
for example ubuntu you can do that executing following commands,
\code
sudo apt-get install valgrind kcachegrind
\endcode
If you are using macOS, you can use Homebrew <http://brew.sh> to make installation,
\code
brew install valgrind
brew install qcachegrind --with-graphviz
\endcode

If you have packages installed, follow instruction from <http://kcachegrind.sourceforge.net/html/Documentation.html>

\section faq_programing Programming

\subsection stop_at_first_error How to stop at first error?

When you compile code and programming, you make errors which produce long error
messages that are diffcult to comprehend. If you like to code stop complying at
the fatal fist error, you can do that by adding to the CMake file
\code
add_definitions(-Wfatal-errors)
\endcode

\note Remove addition to CMake when you push changes. Use -Wfatal-errors only
for debuging and programming.

\subsection adding_user_module How to add user module?

You can see here \ref how_to_add_new_module_and_program or read the following.

MoFEM is a core library providing functionality for implementation of user
modules where applications for particular finite elements or problems are
implemented. User module is an independent repository, private or public and
independently managed by its owner.

User module is added to the project by cloning repository into directory
$HOME/mofem-cephas/mofem/users_modules, for example, module for computational
homogenisation has repository in Bitbucket and can be added by
\code
cd $HOME/mofem-cephas/mofem/users_modules
git clone https://bitbucket.org/likask/mofem_um_homogenisation.git homogenisation
\endcode
Sometimes users modules depend on other modules, in that case, homogenisation
module uses some old obsolete classes (which should not be used in new
developments), thus in this particular case addition you have to clone  also
obsolete module
\code
git clone https://bitbucket.org/likask/mofem_um_obsolete.git obsolete
\endcode

Once the module is added, you have to go main build directory where users
modules are located and rebuild the code. So you have to do
\code
cd $HOME/mofem_build/um
touch CMakeCache.txt
make -j 4
\endcode
Note the first command is used to trigger reconfiguration of users modules with the new module.

Note, each user module consist InstalledAddModule.cmake, with beginning lines,
\code
# Check minimum version of MoFEM with this module works
check_mofem_version(0 5 63)
add_subdirectory(${PROJECT_SOURCE_DIR}/homogenisation)
\endcode
In that file minimal version of the core library is given (e.g. v0.5.63). Thus
if you have too old version of core lib, it won't be added and cmake will
generate an error. In that case, you need to update core library by pulling most
recent version from Bitbucket repository and install core library.

User module can be independent repository, private or public and independently
managed and owned form MoFEM library. If user module is part of MoFEM repository
can be simply added by adding it to \em ModulesLists.cmake in users modules
directory. However is recommended that user module is project/respository by its
own, repository should be cloned to users modules directory, f.e. in
mofem-cephas/mofem/users_modules \code
git clone https://bitbucket.org/likask/mofem_um_homogenisation.git homogenisation
\endcode

In user module directory directory should be file file, \em
InstalledAddModule.cmake, with content,
\code
# Check monimimal version of MoFEM with this module works
check_mofem_version(0 3 6)
add_subdirectory(${PROJECT_SOURCE_DIR}/homogenisation)
\endcode

\subsection openmpi_error_in_docer OpenMPI error in docker

If in docker you have following error
\code
[2761d885210d:00053] Read -1, expected 8192, errno = 1
[2761d885210d:00053] Read -1, expected 87888, errno = 1
[2761d885210d:00054] Read -1, expected 95784, errno = 1
\endcode
Setting in command line
\code
export OMPI_MCA_btl_vader_single_copy_mechanism=none
\endcode
will fix the problem.

\subsection debugging_in_docker How to make debugging in docker?

You can use gdb inside docker, remembering to set cmake with debugging build
type. See \ref spack_developers, and setting `build_type` as explained in \ref
spack_build_type. Now you can run code in docker container and use GDB or
Vagrind to debug code.

\subsection faq_how_to_view_matrix How to view matrix

\note PETSc has to be compiled with X11 library if you like to draw matrix. 

In command line put
\code
-mat_view draw -draw_pause -1 
\endcode

Or you can do that in the code
\code
CHKERR MatView(A, PETSC_VIEWER_DRAW_WORLD);
\endcode


\subsection petsc_print_matrix How to test and print jacobian matrix with PETSc?

When debugging a nonlinear problem, it might be useful to test the jacobian matrix. The command below will print 'Explicit preconditioning Jacobian',
 'Finite difference Jacobian' and the most useful 'User-provided matrix minus finite difference Jacobian'.
\code 
-snes_compare_explicit
\endcode

To view those matrices in a graphical form, simply add:
\code 
-snes_test_jacobian
-snes_compare_explicit_draw 
-draw_save
\endcode

This will create a folder named \e Draw_0x7f86644**** with 3 image files: user-jacobian (0), finite difference jacobian (1) and the difference (2).
The draw function works only with one processor.

If you like to see diffrence of jacobians, add option:
\code
-snes_test_jacobian_display
\endcode

\section fq_visual_studio Visual Studio

\subsection configure_vs_code How to configure MoFEM in Visual Studio Code?

Basic support for C/C++ languages is provided with <a
href="https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools">
Microsoft C/C++ extension</a>. In the CMake files we set option \p
CMAKE_EXPORT_COMPILE_COMMANDS=ON, which results gebration of file \p
compile_commands.json file which has to be added to \p
.vscode/c_cpp_properties.json file located in the working project. %Example \p
c_cpp_properties configuration on Mac should look like follows:

\code
{
    "configurations": [
        {
            "name": "Mac",
            "includePath": [
                "${workspaceFolder}/**"
            ],
            "defines": [
                "WITH_ADOL_C",
                "WITH_TETGEN",
                "WITH_METAIO"
            ],
            "macFrameworkPath": [
                "/System/Library/Frameworks",
                "/Library/Frameworks"
            ],
            "compilerPath": "/usr/bin/clang",
            "cStandard": "gnu17",
            "cppStandard": "gnu++14",
            "intelliSenseMode": "macos-clang-x64",
            "compileCommands": "${workspaceFolder}/um-build-Debug-l3ew3vn/compile_commands.json"
            "browse": {
                "databaseFilename": "${default}",
                "limitSymbolsToIncludedHeaders": true
            }
        }
    ],
    "version": 4
}
\endcode

Note line
\code
"compileCommands": "${workspaceFolder}/um-build-Debug-l3ew3vn/compile_commands.json"
\endcode

which points to the particular build directory, i.e. um-build-Debug-l3ew3vn,
which is associated with spack package hash, i.e. \p l3ew3vn. In this particular
case, we can see 

\code
~ % spack find -lv mofem-users-modules 
==> 2 installed packages
-- darwin-macos-skylake / apple-clang@12.0.0 --------------------
l3ew3vn mofem-users-modules@develop+copy_user_modules~docker~ipo build_type=Debug dev_path=/Users/likask/mofem_install/mofem-cephas/mofem/users_modules install_id=0
\endcode

where fisrt package has hash \p l3ew3vn.

In settings (file .vscode/settings.json), by presing CMD-, (on mac), or CTRL-,
on other systemsm you can choose intelliSenseEngine. "Default" setting for
intelliSenseEngine, is not working or working slow; we recommend switching to
"Tag Parser".

\code
"C_Cpp.intelliSenseEngine": "Tag Parser"
\endcode

However,  "Default" IntelliSense engine is the new engine that provides
semantic-aware IntelliSense features and will be the eventual replacement for
the Tag Parser. So in the future, you can check if the "Default" IntelliSense
engine works well for you. Using  Tag Parser is a temporary solution.

\subsection vs_code_debug How to setup LLDB debugger in Visual Studio Code?

For debugging on Mac the most commonly used extension is <a
href="https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb">
CodeLLDB</a> plugin. The configuration is straightforward: choose \p lldb
type, set the path to the executable (compiled with debug flag!) as \p
program, arguments for the command line put in \p args. Optionally, the path
to current working directory can be set (\p cwd). Example configuration for
fracture module is presented below.
\code 
    "configurations": [
    {
      "type": "lldb",
      "request": "launch",
      "name": "Debug_my_crack1",
      "program": "/Users/User1/moFEM/users_modules_debug/fracture_mechanics/crack_propagation",
      "args": [
        "-my_file",
        "LShape.h5m",
        "-pc_factor_mat_solver_type",
        "mumps",
        "-ksp_monitor"
      ],
      "cwd": "/Users/User1/mofem_install/users_modules_debug/fracture_mechanics"
    }
  ]
\endcode

\section faq_snippets How to iterate over field dofs?

\code

auto iterate_field_row_dofs = [m_field & ](auto field_name, auto prb_name) {
  auto bit_number = m_field.get_field_bit_number(field_name);
  auto prb_ptr = m_field.get_problem(prb_name);
  auto row_dofs_ptr = prb_ptr->getNumeredRowDofsPtr();

  auto lo_it = row_dofs_ptr->get<Unique_mi_tag>().lower_bound(
      FieldEntity::getLoBitNumberUId(bit_number));
  auto hi_it = row_dofs_ptr->get<Unique_mi_tag>().upper_bound(
      FieldEntity::getHiBitNumberUId(bit_number));

  return std::make_pair(lo_it, hi_it);
};

auto iterate_field_and_range_row_dofs = [m_field & ](
                                            auto field_name, auto prb_name,
                                            auto first_ent, auto second_ent) {
  auto bit_number = m_field.get_field_bit_number(field_name);
  auto prb_ptr = m_field.get_problem(prb_name);
  auto row_dofs_ptr = prb_ptr->getNumeredRowDofsPtr();

  auto lo_it = row_dofs_ptr->get<Unique_mi_tag>().lower_bound(
      DofEntity::getLoFieldEntityUId(bit_number, first_ent));
  auto hi_it = row_dofs_ptr->get<Unique_mi_tag>().upper_bound(
      DofEntity::getHiFieldEntityUId(bit_number, second_ent));

  return std::make_pair(lo_it, hi_it);
};


auto iterate_field_and_type_row_dofs = [m_field & ](
                                            auto field_name, auto prb_name) {
  auto bit_number = m_field.get_field_bit_number(field_name);
  auto prb_ptr = m_field.get_problem(prb_name);
  auto row_dofs_ptr = prb_ptr->getNumeredRowDofsPtr();

  // Note is a dynamic variant of get_id_for_min_type, when function takes an
  // argument, not template variable
  auto lo_it = row_dofs_ptr->get<Unique_mi_tag>().lower_bound(
      DofEntity::getLoFieldEntityUId(bit_number,
                                     get_id_for_min_type<MBVERTEX>()));
  auto hi_it = row_dofs_ptr->get<Unique_mi_tag>().upper_bound(
      DofEntity::getHiFieldEntityUId(bit_number,
                                     get_id_for_max_type<MBVERTEX>()));

  return std::make_pair(lo_it, hi_it);
};

\endcode

*/
